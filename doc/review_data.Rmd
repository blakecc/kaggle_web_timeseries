---
title: "Reviewing data"
output: html_notebook
---

# Load libraries
```{r}
library(tidyverse)
library(stringr)
library(lubridate)

```

# Load data

```{r}
library(data.table)

rm(list = ls())

train_1 <- fread("data/train_1.csv", header = T, encoding = "UTF-8")
key_1 <- fread("data/key_1.csv", header = T, encoding = "UTF-8")
sample_submission_1 <- fread("data/sample_submission_1.csv", header = T, encoding = "UTF-8")

# head(sample_submission_1, 10)
# head(key_1, 10)
# head(train_1[,551], 10)

```

# Extract one series and experiment

```{r}
rm(list = ls())

train_1 <- fread("data/train_1.csv", header = T, encoding = "UTF-8")

carrie_f_test <- train_1 %>%
  # arrange(desc(`2016-12-31`)) %>%
  filter(Page == "Carrie_Fisher_en.wikipedia.org_all-access_all-agents") %>%
  gather(-Page, key = Date, value = Visits) %>%
  mutate(Date = as.Date(Date))

rm(train_1)
```
```{r}

# basic regression trend
carrie_trend <- lm(Visits ~ Date, data = carrie_f_test)

# Plot trends and data
carrie_f_test %>%
  ggplot(aes(x = Date, y = Visits)) + geom_line() + geom_hline(yintercept = mean(carrie_f_test$Visits), colour = "blue") + geom_abline(slope = 1.835e+02, intercept = -3.067e+06, colour = "red")

# create predicted dates vector
pred_dates <- rep(carrie_f_test$Date[550], 60) + seq(from = 1, to = 60, by = 1)

# predict visits
## predict trend
pred_visits_trend <- ceiling(predict.lm(carrie_trend, newdata = data.frame(Date = pred_dates)))

## final value
last_observed_value <- carrie_f_test$Visits[nrow(carrie_f_test)]

## predict trend correction
correction_length <- 10
pred_correction <- numeric(correction_length)
pred_correction[1] <- (last_observed_value - pred_visits_trend[1]) / 2
for (i in 2:correction_length){
  last_observed_value <- pred_visits_trend[i-1] + pred_correction[i-1]   
  pred_correction[i] <- (last_observed_value - pred_visits_trend[i]) / 2
}

## add correction to trend
pred_visits <- numeric(60)
pred_visits <- pred_visits_trend[1:length(pred_visits_trend)]
pred_visits[1:correction_length] <- pred_visits_trend[1:correction_length] + pred_correction


# add predictions to data
carrie_predictions <- data.frame(Page = rep(carrie_f_test$Page[1], 60),
                                 Date = pred_dates,
                                 Visits = pred_visits)

carrie_combined <- rbind(carrie_f_test, carrie_predictions)

# Plot prediction
carrie_combined %>%
  ggplot(aes(x = Date, y = Visits)) +
    geom_line() +
    geom_vline(xintercept = as.numeric(carrie_combined$Date[551]), colour = "blue", linetype = 2)



```


# Split key

```{r}
key_sep <- key_1 %>%
  separate(Page, c("Page", "Date"), sep = -11) %>%
  mutate(Page = str_sub(Page, 1, -2))

# Test page occurence in Train data

sum(!train_1$Page %in% key_sep$Page) / length(train_1$Page) # only 54% match
nomatch_test <- train_1$Page[!train_1$Page %in% key_sep$Page][1]

key_zh_sample <- key_sep %>%
  # filter(Page == nomatch_test) %>%
  filter(str_detect(Page, "zh.wikipedia.org_all-access_spider")) %>%
  sample_n(100)

train_zh_sample <- train_1 %>%
  filter(str_detect(Page, "zh.wikipedia.org_all-access_spider")) %>%
  sample_n(100)

print(key_zh_sample[1,]$Page)
print(train_zh_sample[1,]$Page)

#   mutate(Other = str_sub(Other, 2)) %>%
#   mutate(Lang = str_sub(Lang, 1, -2)) %>%
#   separate(Other, c("device", "agent", "date"), sep = "_") %>%
#   mutate(Topic = str_sub(Topic, 1, -2)) %>%
#   mutate(date = as.POSIXct(date))
# 
# key_1[2220:2230,]
# key_1[2020:2030,]

```

# Construct sample submission

```{r}

# average of last 10 days for train data
train_1$MA_10 <- apply(train_1[,540:551], 1, mean, na.rm = T) # last ten days MA
# train_1$MA_10 <- train_1[,551] # last value

# train_1 %>%
#   select(Page, MA_10) %>%
#   filter(Page == "\"\"Keep_me_logged_in\"\"_extended_to_one_year_www.mediawiki.org_all-access_all-agents")

train_2 <- train_1 %>%
  select(Page, MA_10)

# head(train_2)

test_submission <- left_join(key_sep, train_2, by = "Page")
# head(test_submission)
# head(sample_submission_1)

submission1 <- test_submission %>%
  mutate(MA_10 = ceiling(MA_10)) %>%
  rename(Visits = MA_10) %>%
  select(Id, Visits) %>%
  mutate(Visits = ifelse(is.na(Visits), 0, Visits)) %>%
  mutate(Visits = as.integer(Visits))

write_csv(submission1, "output/key.csv")


# head(submission1)
# head(sample_submission_1)

# head(test_submission, 1000)
# train_1[,c(1,551)]
# 
# train_1[train_1$Page == ".ca_ru.wikipedia.org_desktop_all-agents"][,c(1,540:552)]
```

```{r}
submission1 %>%
  filter(Visits <= 50) %>%
  ggplot(aes(Visits)) +
    geom_histogram(bins = 50)

# mean(c(1,2,3,4,NA), na.rm = T)

```